---
title: "NVIDIA DLER - Home"
layout: homelay
excerpt: "NVIDIA Deep Learning Efficiency Research"
sitemap: false
permalink: /
---

<img src="images/nvidia_logo.png" width="256" align="right">

Welcome to the Deep Learning Efficiency Research (DLER) team at [NVIDIA Research](https://www.nvidia.com/en-us/research/) led by [Dr. Pavlo Molchanov](https://www.pmolchanov.com). 

Founded in 2023, we are a vibrant and dynamic research lab. Many of our team members have been with NVIDIA for over five years. We operate under the umbrella of the [Learning and Perception Research (LPR)](https://research.nvidia.com/labs/lpr/) group, led by [Dr. Jan Kautz](https://jankautz.com). 

<!-- Our interests include the development of new architectures and method for efficient LLM inference and training, pre-training of small language models, development of efficient Vision Language models, and general improvements of deep learning models with an eye on their memory footprint, inference latency, and energy consumption. -->

Our mission is to drive advancements in the efficiency of deep learning technologies, focusing on reducing memory footprint, minimizing inference latency, and lowering energy consumption.

We are particularly interested in:
   - Exploring applications of Large Language Models (LLMs) and Multi-Modal Language Models.
   - Enhancing post-training model optimization through techniques such as compression, sparsity, quantization, and Neural Architecture Search (NAS).
   - Designing novel and efficient architectures.
   - Dynamic and adaptive model inference
   - Developing innovative training paradigms

<br clear="left"/>

**We are actively seeking exceptional deep learning researchers.** Explore opportunities at the [NVIDIA Careers website](https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite) or reach out directly to our team members via email.


